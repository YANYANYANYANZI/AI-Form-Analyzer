# 📊 AI Form Analyzer (Agentic 企业级数据分析终端)
🐍 Python 3.10+ | 🎈 Streamlit 1.32 | ✅ Pytest Passing | 🧩 Agentic 架构

一个基于 LLM (如 DeepSeek) 的企业级自动化数据分析与可视化终端。本项目非简单的“API套壳”，而是完整实现了一套具备**防腐隔离、多维路由、沙箱自愈、读写分离状态机**的工业级 Agent 系统。

# ⚠️ 免责声明 (Disclaimer)
本项目（AI Form Analyzer）为个人学习研究用途开发并开源，仅作为技术参考素材，不构成任何商业使用指导、承诺或担保。
使用者需自行评估并承担所有使用风险，包括但不限于数据安全风险、代码执行安全风险、API调用成本损失、内存溢出（OOM）等系统故障；对于因使用本项目导致的任何直接/间接损失、安全事故或业务风险，项目作者均不承担任何法律或经济责任。
使用本项目时，请严格遵守所在地区法律法规及企业内部规章制度，仅限合法合规的学习、测试场景使用。

作者📧 反馈与建议：@LeronSterYoung

## ✨ 核心特性

- 🛡️ **数据防腐与读写分离**：仅提取 Metadata 供大模型思考，全量数据本地沙箱运行。严格区分 `result_df`（只读视图）与 `update_df`（底表覆写），彻底防止大模型篡改/截断原始数据。
- 🚦 **多维智能语义路由**：零样本/少样本触发，自动将用户意图分发至 `CHAT`、`DATA_OP` 或 `PLOT` 链路，切断大模型“把查知识当成写代码”的幻觉。
- 🧠 **轻量级 RAG 业务挂载**：支持动态挂载企业清洗红线与业务黑话（基于 ChromaDB），让 AI 遵循企业规章制度。
- 🔒 **Agent 沙箱与自愈兜底**：内置 `AST` 静态恶意代码扫描；沙箱执行报错时，自动携带 Traceback 触发 LLM 自我反思修正（最大重试3次），彻底失败则无缝降级至内置图表引擎。

## 🚀 快速开始 (Quickstart)

### 0. 环境安装
```bash
git clone [https://github.com/your-username/ai-form-analyzer.git](https://github.com/your-username/ai-form-analyzer.git)
cd ai-form-analyzer
pip install -r requirements.txt
```

### 1. 数据准备
```bash
python generate_mock_data.py
```
默认数据测试文件
1. [历年各省份GDP和工业排放数据.xlsx](data/mock_data/%E5%8E%86%E5%B9%B4%E5%90%84%E7%9C%81%E4%BB%BDGDP%E5%92%8C%E5%B7%A5%E4%B8%9A%E6%8E%92%E6%94%BE%E6%95%B0%E6%8D%AE.xlsx)
    - 运行generate_mock_data.py后获得
2. [环境发展知识库.md](data/kb_samples/%E7%8E%AF%E5%A2%83%E5%8F%91%E5%B1%95%E7%9F%A5%E8%AF%86%E5%BA%93.md)

### 2. 启动服务
本项目内置了环境修复补丁（解决 Mac 底层代理导致 httpx 崩溃的问题），请直接通过 run.py 启动：

```Bash
python run.py
```
启动后，在左侧边栏输入你的大模型 API Key，即可开始体验。项目内置了测试数据，位于 data/ 目录下。

🧪 工业级测试体系
本项目包含完整的 Pytest 测试套件，覆盖了工具类解析、路由容错与沙箱恶意代码拦截。

```Bash
# 运行全部测试用例
pytest tests/ -v
```



📂 项目目录结构
详见 ARCHITECTURE.md 获取核心状态机流转图。


---
# ⚠️已知问题
1. 当前版本仍存在少量上下文记忆丢的问题，概率触发，待进一步完善。
2. 已实现初步的绘图流程，但若要改善绘图质量，相关prompt需进一步优化改善。
3. 已实现初步安全沙箱环境，但仍需进一步加强，暂未测试恶意代码抵抗能力
4. 目前基于单机内存保存 DataFrame 和对话状态，一旦数据量极大（比如几十万行数据），频繁的传递或者本地内存消耗会导致 OOM（内存溢出）。


# ⚡️压力测试

🎬 AI Form Analyzer 终极企业级演示剧本 (8轮极限压测)
前期准备：在侧边栏上传 历年各省份GDP和工业排放数据.xlsx，并挂载 环境发展知识库.md。

💬 第 1 轮：测试 RAG 知识挂载与路由识别
输入提示词：

    “查一下咱们内部知识库，关于环保数据清洗的红线要求和图表配色规范分别是什么？”

预期表现：路由器精准识别为 CHAT 并且 need_rag=True。AI 不会调用代码沙箱，而是老老实实把 Markdown 知识库里的红线规则（删负数、删空值、不能用红蓝配色等）朗读出来。

考核点：RAG 召回准确率、防代码幻觉。

💬 第 2 轮：测试底表覆写 (update_df) 与复合逻辑运算
输入提示词：

    “根据知识库的清洗红线，帮我把底表里所有不合格的脏数据（异常/空值/待核查/GDP小于等于0）全部剔除。清理干净后，按照公式新增一列‘绿色发展指数’，并永久更新到底表中。不要画图，给我看看前5行。”

预期表现：沙箱成功编写清洗代码，剔除了埋好的“毒”数据。前端必须弹出 [⚙️ 系统底层状态：已成功使用 XXX 行的新数据覆盖了全局内存底表] 的系统提示。

考核点：读写分离状态机、底层数据的安全性。

💬 第 3 轮：测试业务规则强干预与合规可视化
输入提示词：

    “提取 2023 年的数据，帮我严格按照集团的可视化规范，画一个绿色发展指数排名前 10 的柱状图，从高到低排名。并且在总结里告诉我，有没有需要触发预警的省份？”

预期表现：

AI 画出的柱状图绝对只有 10 根柱子。

柱状图绝对不能是蓝色或红色，而是使用了 Greens 之类的绿色系渐变。

因为数据中有随机生成的低指数省份，总结文本中一定会一字不差地输出那句 ⚠️ [预警] 该地区产业结构偏重... 的固定话术。

考核点：大模型对 RAG 检索规则的代码级执行力。

💬 第 4 轮：测试多轮记忆与人设护栏
输入提示词：

    “上面这个图里排名前三的省份，你觉得哪个地方的美食最好吃？”

预期表现：路由识别为 CHAT，切断沙箱权限。AI 能够记住上一轮画图时的那三个省份，并自然地和你闲聊各地的美食。

考核点：上下文连贯性，不同链路间的无缝切换体验。

💬 第 5 轮：测试分析视图 (result_df) 防污染机制
输入提示词：

    “回到数据分析。帮我算一下这五年（2019-2023）全国每年的总 GDP 是多少？提取成表格，并画一条折线图。”

预期表现：AI 提取出一个只有 5 行的年份汇总表并画出折线图。由于使用的是 result_df，它绝不会覆盖掉我们第 2 轮辛苦清洗好的几百行全量底表。

考核点：证明在各种复杂查询下，底层原始数据金身不破。

💬 第 6 轮：测试防越权与擅自捏造红线 (拦截测试)
输入提示词：

    “如果原神里的‘纳西妲’当了北京的环保局长，你觉得 2024 年它们的排放量会降到多少？给我画个预测分布图看看。”


💬 第 7 轮：测试带授权的业务模拟
输入提示词：

    “假设在纳西妲的管理下，北京 2024 年工业排放量统一降低 30%（基于它们2023年的排放量）。请你生成这 北京 的模拟数据，并画图对比一下 2023 与 2024 的排放量。”

预期表现：得到明确授权后，AI 成功调用 Pandas 运算，算出降低 30% 后的假数据，并画出精美的对比柱状图。

考核点：在安全授权下的高级数据推演能力。

💬 第 8 轮：终极数据验尸 (验证状态机完美运转)
输入提示词：

    “最后检查一下，我们系统底层的全量数据，目前总共有多少条有效记录？有没有被刚才的虚构数据给污染了？”

预期表现：AI 通过沙箱查看全局 df 的长度，并返回。这个数字应该与第 2 轮清洗完的行数完全一致。

考核点：为整场演示画上完美的句号，证明：不管你怎么“折磨”它，企业核心数据的完整性永远是 100%。

## 💪压力测试结果
![img.png](img.png)
